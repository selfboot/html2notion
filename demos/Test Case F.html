<?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><meta name="exporter-version" content="Evernote Mac 9.6.8 (470886)"/><meta name="created" content="2023-04-28 08:56:16 +0000"/><meta name="source" content="web.clip7"/><meta name="source-application" content="webclipper.evernote"/><meta name="source-url" content="https://platform.openai.com/docs/guides/rate-limits/request-increase"/><meta name="updated" content="2023-04-28 08:56:16 +0000"/><title>Rate Limits - OpenAI API</title></head><body>
  <div style="--en-clipped-content:article; --en-clipped-source-url:https://platform.openai.com/docs/guides/rate-limits/request-increase; --en-clipped-source-title:Rate Limits - OpenAI API;">
<div><br/></div><div style="min-height: 5333px; font-size: 16px; display: block; min-width: 100%; position: relative;"> <div style="-webkit-font-smoothing:antialiased;color:rgb(53, 55, 64);font-family:ColfaxAI, helvetica, sans-serif;font-size:16px;box-sizing:border-box;"><div style="-webkit-font-smoothing:antialiased;color:rgb(53, 55, 64);font-family:ColfaxAI, helvetica, sans-serif;font-size:16px;box-sizing:border-box;"><div style="box-sizing:border-box;overflow:auto;"><div style="box-sizing:border-box;"><div style="color:rgb(53, 55, 64);box-sizing:border-box;"><div style="box-sizing:border-box;font-size:16px;line-height:24px;"><div style="box-sizing:border-box;min-width:0px;overflow:auto;"><div style="box-sizing:border-box;"><div style="box-sizing:border-box;margin-bottom:16px;margin-top:0px;"><a href="https://platform.openai.com/docs/guides/rate-limits/rate-limits" style="box-sizing:border-box;color:rgb(16, 163, 127);cursor:pointer;text-decoration:none;display:inline-block;"><h1 style="box-sizing:border-box;color:rgb(32, 33, 35);font-weight:700;margin-bottom:0px;font-size:32px;line-height:40px;margin-top:0px;margin:0px;position:relative;">Rate limits<img src="Rate%20Limits%20-%20OpenAI%20API.resources/svg_1.svg"/></h1></a></div><div style="box-sizing:border-box;margin-bottom:16px;margin-top:30px;"><a href="https://platform.openai.com/docs/guides/rate-limits/overview" style="box-sizing:border-box;color:rgb(16, 163, 127);cursor:pointer;text-decoration:none;display:inline-block;"><h2 style="box-sizing:border-box;color:rgb(32, 33, 35);font-weight:700;margin-bottom:0px;font-size:24px;line-height:32px;margin-top:0px;margin:0px;position:relative;">Overview<img src="Rate%20Limits%20-%20OpenAI%20API.resources/svg_2.svg"/></h2></a></div><div style="box-sizing:border-box;margin-bottom:16px;margin-top:30px;"><a href="https://platform.openai.com/docs/guides/rate-limits/what-are-rate-limits" style="box-sizing:border-box;color:rgb(16, 163, 127);cursor:pointer;text-decoration:none;display:inline-block;"><h3 style="box-sizing:border-box;color:rgb(32, 33, 35);font-weight:700;margin-bottom:0px;font-size:20px;line-height:28px;margin-top:0px;margin:0px;position:relative;">What are rate limits?<img src="Rate%20Limits%20-%20OpenAI%20API.resources/svg_3.svg"/></h3></a></div><p style="box-sizing:border-box;margin-bottom:15px;margin-top:0px;line-height:1.5;">A rate limit is a restriction that an API imposes on the number of times a user or client can access the server within a specified period of time. </p><div style="box-sizing:border-box;margin-bottom:16px;margin-top:30px;"><a href="https://platform.openai.com/docs/guides/rate-limits/why-do-we-have-rate-limits" style="box-sizing:border-box;color:rgb(16, 163, 127);cursor:pointer;text-decoration:none;display:inline-block;"><h3 style="box-sizing:border-box;color:rgb(32, 33, 35);font-weight:700;margin-bottom:0px;font-size:20px;line-height:28px;margin-top:0px;margin:0px;position:relative;">Why do we have rate limits?<img src="Rate%20Limits%20-%20OpenAI%20API.resources/svg_4.svg"/></h3></a></div><p style="box-sizing:border-box;margin-bottom:15px;margin-top:0px;line-height:1.5;">Rate limits are a common practice for APIs, and they're put in place for a few different reasons:</p><ul style="box-sizing:border-box;list-style:none;padding-left:0px;"><li style="box-sizing:border-box;line-height:1.4;padding-left:32px;position:relative;"><strong style="box-sizing:border-box;">They help protect against abuse or misuse of the API.</strong> For example, a malicious actor could flood the API with requests in an attempt to overload it or cause disruptions in service. By setting rate limits, OpenAI can prevent this kind of activity.</li><li style="box-sizing:border-box;line-height:1.4;padding-left:32px;position:relative;margin-top:8px;"><strong style="box-sizing:border-box;">Rate limits help ensure that everyone has fair access to the API.</strong> If one person or organization makes an excessive number of requests, it could bog down the API for everyone else. By throttling the number of requests that a single user can make, OpenAI ensures that the most number of people have an opportunity to use the API without experiencing slowdowns.</li><li style="box-sizing:border-box;line-height:1.4;padding-left:32px;position:relative;margin-top:8px;"><strong style="box-sizing:border-box;">Rate limits can help OpenAI manage the aggregate load on its infrastructure.</strong> If requests to the API increase dramatically, it could tax the servers and cause performance issues. By setting rate limits, OpenAI can help maintain a smooth and consistent experience for all users.</li></ul><div style="box-sizing:border-box;margin-top:24px;margin-bottom:24px;"><div style="box-sizing:border-box;border:1px solid rgb(236, 236, 241);border-radius:4px;flex:0 0 auto;min-width:275px;padding:16px 18px;position:relative;text-align:center;width:100%;align-items:center;display:inline-flex;background-color:rgb(247, 247, 248);border-color:rgb(236, 236, 241);"><div style="box-sizing:border-box;font-size:20px;display:inline-flex;flex:0 0 auto;margin-right:14px;color:rgb(110, 110, 128);align-self:flex-start;"><img src="Rate%20Limits%20-%20OpenAI%20API.resources/svg_5.svg"/></div><div style="box-sizing:border-box;color:rgb(32, 33, 35);margin-bottom:-2px;text-align:left;flex:1 1 auto;"><div style="box-sizing:border-box;">Please work through this document in its entirety to better understand how OpenAIâ€™s rate limit system works. We include code examples and possible solutions to handle common issues. It is recommended to follow this guidance before filling out the <a href="https://docs.google.com/forms/d/e/1FAIpQLSc6gSL3zfHFlL6gNIyUcjkEv29jModHGxg5_XGyr-PrE2LaHw/viewform" target="_blank" rel="noopener noreferrer" style="box-sizing:border-box;cursor:pointer;color:rgb(16, 163, 127);text-decoration:none;font-weight:400;">Rate Limit Increase Request form</a> with details regarding how to fill it out in the last section.</div></div></div></div><div style="box-sizing:border-box;margin-bottom:16px;margin-top:30px;"><a href="https://platform.openai.com/docs/guides/rate-limits/what-are-the-rate-limits-for-our-api" style="box-sizing:border-box;color:rgb(16, 163, 127);cursor:pointer;text-decoration:none;display:inline-block;"><h3 style="box-sizing:border-box;color:rgb(32, 33, 35);font-weight:700;margin-bottom:0px;font-size:20px;line-height:28px;margin-top:0px;margin:0px;position:relative;">What are the rate limits for our API?<img src="Rate%20Limits%20-%20OpenAI%20API.resources/svg_6.svg"/></h3></a></div><p style="box-sizing:border-box;margin-bottom:15px;margin-top:0px;line-height:1.5;">We enforce rate limits at the <a href="https://platform.openai.com/docs/guides/production-best-practices" style="box-sizing:border-box;color:rgb(16, 163, 127);cursor:pointer;text-decoration:none;">organization level</a>, not user level, based on the specific endpoint used as well as the type of account you have. Rate limits are measured in two ways: <strong style="box-sizing:border-box;">RPM</strong> (requests per minute) and <strong style="box-sizing:border-box;">TPM</strong> (tokens per minute). The table below highlights the default rate limits for our API but these limits can be increased depending on your use case after filling out the Rate Limit increase request form.</p><p style="box-sizing:border-box;margin-bottom:15px;margin-top:0px;line-height:1.5;">The <strong style="box-sizing:border-box;">TPM</strong> (tokens per minute) unit is different depending on the model:</p><table style="font-size:inherit;font-weight:inherit;font-style:inherit;font-variant:inherit;box-sizing:border-box;border-collapse:collapse;margin:20px 0px 15px;"><thead style="box-sizing:border-box;"><tr style="box-sizing:border-box;"><th style="box-sizing:border-box;border:none;color:rgb(32, 33, 35);font-size:12px;font-weight:700;letter-spacing:0.1em;line-height:16px;padding:0px 8px 3px;text-align:left;text-transform:uppercase;vertical-align:bottom;padding-left:0px;">type</th><th style="box-sizing:border-box;border:none;color:rgb(32, 33, 35);font-size:12px;font-weight:700;letter-spacing:0.1em;line-height:16px;padding:0px 8px 3px;text-align:left;text-transform:uppercase;vertical-align:bottom;padding-right:0px;">1 TPM equals</th></tr></thead><tbody style="box-sizing:border-box;"><tr style="box-sizing:border-box;"><td style="box-sizing:border-box;border-right:none;border-bottom:none;border-left:none;border-image:initial;border-top:1px solid rgb(236, 236, 241);padding:8px;vertical-align:top;padding-left:0px;">davinci</td><td style="box-sizing:border-box;border-right:none;border-bottom:none;border-left:none;border-image:initial;border-top:1px solid rgb(236, 236, 241);padding:8px;vertical-align:top;padding-right:0px;">1 token per minute</td></tr><tr style="box-sizing:border-box;"><td style="box-sizing:border-box;border-right:none;border-bottom:none;border-left:none;border-image:initial;border-top:1px solid rgb(236, 236, 241);padding:8px;vertical-align:top;padding-left:0px;">curie</td><td style="box-sizing:border-box;border-right:none;border-bottom:none;border-left:none;border-image:initial;border-top:1px solid rgb(236, 236, 241);padding:8px;vertical-align:top;padding-right:0px;">25 tokens per minute</td></tr><tr style="box-sizing:border-box;"><td style="box-sizing:border-box;border-right:none;border-bottom:none;border-left:none;border-image:initial;border-top:1px solid rgb(236, 236, 241);padding:8px;vertical-align:top;padding-left:0px;">babbage</td><td style="box-sizing:border-box;border-right:none;border-bottom:none;border-left:none;border-image:initial;border-top:1px solid rgb(236, 236, 241);padding:8px;vertical-align:top;padding-right:0px;">100 tokens per minute</td></tr><tr style="box-sizing:border-box;"><td style="box-sizing:border-box;border-right:none;border-bottom:none;border-left:none;border-image:initial;border-top:1px solid rgb(236, 236, 241);padding:8px;vertical-align:top;padding-left:0px;">ada</td><td style="box-sizing:border-box;border-right:none;border-bottom:none;border-left:none;border-image:initial;border-top:1px solid rgb(236, 236, 241);padding:8px;vertical-align:top;padding-right:0px;">200 tokens per minute</td></tr></tbody></table><p style="box-sizing:border-box;margin-bottom:15px;margin-top:0px;line-height:1.5;">In practical terms, this means you can send approximately 200x more tokens per minute to an <code style="box-sizing:border-box;background:rgba(237, 238, 241, 0.5);border:1px solid rgba(174, 174, 188, 0.2);border-radius:4px;font-family:&quot;Roboto Mono&quot;, sfmono-regular, consolas, &quot;liberation mono&quot;, menlo, courier, monospace;font-size:14px;font-weight:500;margin:0px 2px;padding:2px 4px;">ada</code> model versus a <code style="box-sizing:border-box;background:rgba(237, 238, 241, 0.5);border:1px solid rgba(174, 174, 188, 0.2);border-radius:4px;font-family:&quot;Roboto Mono&quot;, sfmono-regular, consolas, &quot;liberation mono&quot;, menlo, courier, monospace;font-size:14px;font-weight:500;margin:0px 2px;padding:2px 4px;">davinci</code> model.</p><div style="box-sizing:border-box;overflow-x:auto;"><div style="box-sizing:border-box;min-width:600px;"><table style="font-size:inherit;font-weight:inherit;font-style:inherit;font-variant:inherit;box-sizing:border-box;border-collapse:collapse;margin:20px 0px 15px;"><thead style="box-sizing:border-box;"><tr style="box-sizing:border-box;"><th style="box-sizing:border-box;border:none;color:rgb(32, 33, 35);font-size:12px;font-weight:700;letter-spacing:0.1em;line-height:16px;padding:0px 8px 3px;text-align:left;text-transform:uppercase;vertical-align:bottom;padding-left:0px;"/><th style="box-sizing:border-box;border:none;color:rgb(32, 33, 35);font-size:12px;font-weight:700;letter-spacing:0.1em;line-height:16px;padding:0px 8px 3px;text-align:left;text-transform:uppercase;vertical-align:bottom;">Text &amp; Embedding</th><th style="box-sizing:border-box;border:none;color:rgb(32, 33, 35);font-size:12px;font-weight:700;letter-spacing:0.1em;line-height:16px;padding:0px 8px 3px;text-align:left;text-transform:uppercase;vertical-align:bottom;">Chat</th><th style="box-sizing:border-box;border:none;color:rgb(32, 33, 35);font-size:12px;font-weight:700;letter-spacing:0.1em;line-height:16px;padding:0px 8px 3px;text-align:left;text-transform:uppercase;vertical-align:bottom;">Codex</th><th style="box-sizing:border-box;border:none;color:rgb(32, 33, 35);font-size:12px;font-weight:700;letter-spacing:0.1em;line-height:16px;padding:0px 8px 3px;text-align:left;text-transform:uppercase;vertical-align:bottom;">Edit</th><th style="box-sizing:border-box;border:none;color:rgb(32, 33, 35);font-size:12px;font-weight:700;letter-spacing:0.1em;line-height:16px;padding:0px 8px 3px;text-align:left;text-transform:uppercase;vertical-align:bottom;">Image</th><th style="box-sizing:border-box;border:none;color:rgb(32, 33, 35);font-size:12px;font-weight:700;letter-spacing:0.1em;line-height:16px;padding:0px 8px 3px;text-align:left;text-transform:uppercase;vertical-align:bottom;padding-right:0px;">Audio</th></tr></thead><tbody style="box-sizing:border-box;"><tr style="box-sizing:border-box;"><td style="box-sizing:border-box;border-right:none;border-bottom:none;border-left:none;border-image:initial;border-top:1px solid rgb(236, 236, 241);padding:8px;vertical-align:top;padding-left:0px;">Free trial users</td><td style="box-sizing:border-box;border-right:none;border-bottom:none;border-left:none;border-image:initial;border-top:1px solid rgb(236, 236, 241);padding:8px;vertical-align:top;">3 RPM <br style="box-sizing:border-box;"/> 150,000 TPM</td><td style="box-sizing:border-box;border-right:none;border-bottom:none;border-left:none;border-image:initial;border-top:1px solid rgb(236, 236, 241);padding:8px;vertical-align:top;">3 RPM <br style="box-sizing:border-box;"/> 40,000 TPM</td><td style="box-sizing:border-box;border-right:none;border-bottom:none;border-left:none;border-image:initial;border-top:1px solid rgb(236, 236, 241);padding:8px;vertical-align:top;">3 RPM <br style="box-sizing:border-box;"/> 40,000 TPM</td><td style="box-sizing:border-box;border-right:none;border-bottom:none;border-left:none;border-image:initial;border-top:1px solid rgb(236, 236, 241);padding:8px;vertical-align:top;">3 RPM <br style="box-sizing:border-box;"/> 150,000 TPM</td><td style="box-sizing:border-box;border-right:none;border-bottom:none;border-left:none;border-image:initial;border-top:1px solid rgb(236, 236, 241);padding:8px;vertical-align:top;">5 images / min</td><td style="box-sizing:border-box;border-right:none;border-bottom:none;border-left:none;border-image:initial;border-top:1px solid rgb(236, 236, 241);padding:8px;vertical-align:top;padding-right:0px;">3 RPM</td></tr><tr style="box-sizing:border-box;"><td style="box-sizing:border-box;border-right:none;border-bottom:none;border-left:none;border-image:initial;border-top:1px solid rgb(236, 236, 241);padding:8px;vertical-align:top;padding-left:0px;">Pay-as-you-go users (first 48 hours)</td><td style="box-sizing:border-box;border-right:none;border-bottom:none;border-left:none;border-image:initial;border-top:1px solid rgb(236, 236, 241);padding:8px;vertical-align:top;">60 RPM <br style="box-sizing:border-box;"/> 250,000 TPM</td><td style="box-sizing:border-box;border-right:none;border-bottom:none;border-left:none;border-image:initial;border-top:1px solid rgb(236, 236, 241);padding:8px;vertical-align:top;">60 RPM <br style="box-sizing:border-box;"/> 60,000 TPM</td><td style="box-sizing:border-box;border-right:none;border-bottom:none;border-left:none;border-image:initial;border-top:1px solid rgb(236, 236, 241);padding:8px;vertical-align:top;">20 RPM <br style="box-sizing:border-box;"/> 40,000 TPM</td><td style="box-sizing:border-box;border-right:none;border-bottom:none;border-left:none;border-image:initial;border-top:1px solid rgb(236, 236, 241);padding:8px;vertical-align:top;">20 RPM <br style="box-sizing:border-box;"/> 150,000 TPM</td><td style="box-sizing:border-box;border-right:none;border-bottom:none;border-left:none;border-image:initial;border-top:1px solid rgb(236, 236, 241);padding:8px;vertical-align:top;">50 images / min</td><td style="box-sizing:border-box;border-right:none;border-bottom:none;border-left:none;border-image:initial;border-top:1px solid rgb(236, 236, 241);padding:8px;vertical-align:top;padding-right:0px;">50 RPM</td></tr><tr style="box-sizing:border-box;"><td style="box-sizing:border-box;border-right:none;border-bottom:none;border-left:none;border-image:initial;border-top:1px solid rgb(236, 236, 241);padding:8px;vertical-align:top;padding-left:0px;">Pay-as-you-go users (after 48 hours)</td><td style="box-sizing:border-box;border-right:none;border-bottom:none;border-left:none;border-image:initial;border-top:1px solid rgb(236, 236, 241);padding:8px;vertical-align:top;">3,500 RPM <br style="box-sizing:border-box;"/> 350,000 TPM</td><td style="box-sizing:border-box;border-right:none;border-bottom:none;border-left:none;border-image:initial;border-top:1px solid rgb(236, 236, 241);padding:8px;vertical-align:top;">3,500 RPM <br style="box-sizing:border-box;"/> 90,000 TPM</td><td style="box-sizing:border-box;border-right:none;border-bottom:none;border-left:none;border-image:initial;border-top:1px solid rgb(236, 236, 241);padding:8px;vertical-align:top;">20 RPM <br style="box-sizing:border-box;"/> 40,000 TPM</td><td style="box-sizing:border-box;border-right:none;border-bottom:none;border-left:none;border-image:initial;border-top:1px solid rgb(236, 236, 241);padding:8px;vertical-align:top;">20 RPM <br style="box-sizing:border-box;"/> 150,000 TPM</td><td style="box-sizing:border-box;border-right:none;border-bottom:none;border-left:none;border-image:initial;border-top:1px solid rgb(236, 236, 241);padding:8px;vertical-align:top;">50 images / min</td><td style="box-sizing:border-box;border-right:none;border-bottom:none;border-left:none;border-image:initial;border-top:1px solid rgb(236, 236, 241);padding:8px;vertical-align:top;padding-right:0px;">50 RPM</td></tr></tbody></table></div></div><p style="box-sizing:border-box;margin-bottom:15px;margin-top:0px;line-height:1.5;">It is important to note that the rate limit can be hit by either option depending on what occurs first. For example, you might send 20 requests with only 100 tokens to the Codex endpoint and that would fill your limit, even if you did not send 40k tokens within those 20 requests.</p><div style="box-sizing:border-box;margin-bottom:16px;margin-top:30px;"><a href="https://platform.openai.com/docs/guides/rate-limits/gpt-4-rate-limits" style="box-sizing:border-box;color:rgb(16, 163, 127);cursor:pointer;text-decoration:none;display:inline-block;"><h4 style="box-sizing:border-box;color:rgb(32, 33, 35);font-weight:700;margin-bottom:0px;font-size:18px;line-height:24px;margin-top:0px;margin:0px;position:relative;">GPT-4 rate limits<img src="Rate%20Limits%20-%20OpenAI%20API.resources/svg_7.svg"/></h4></a></div><p style="box-sizing:border-box;margin-bottom:15px;margin-top:0px;line-height:1.5;">During the limited beta rollout of GPT-4, the model will have more aggressive rate limits to keep up with demand. Default rate limits for <code style="box-sizing:border-box;background:rgba(237, 238, 241, 0.5);border:1px solid rgba(174, 174, 188, 0.2);border-radius:4px;font-family:&quot;Roboto Mono&quot;, sfmono-regular, consolas, &quot;liberation mono&quot;, menlo, courier, monospace;font-size:14px;font-weight:500;margin:0px 2px;padding:2px 4px;">gpt-4</code>/<code style="box-sizing:border-box;background:rgba(237, 238, 241, 0.5);border:1px solid rgba(174, 174, 188, 0.2);border-radius:4px;font-family:&quot;Roboto Mono&quot;, sfmono-regular, consolas, &quot;liberation mono&quot;, menlo, courier, monospace;font-size:14px;font-weight:500;margin:0px 2px;padding:2px 4px;">gpt-4-0314</code> are 40k TPM and 200 RPM. Default rate limits for  <code style="box-sizing:border-box;background:rgba(237, 238, 241, 0.5);border:1px solid rgba(174, 174, 188, 0.2);border-radius:4px;font-family:&quot;Roboto Mono&quot;, sfmono-regular, consolas, &quot;liberation mono&quot;, menlo, courier, monospace;font-size:14px;font-weight:500;margin:0px 2px;padding:2px 4px;">gpt-4-32k</code>/<code style="box-sizing:border-box;background:rgba(237, 238, 241, 0.5);border:1px solid rgba(174, 174, 188, 0.2);border-radius:4px;font-family:&quot;Roboto Mono&quot;, sfmono-regular, consolas, &quot;liberation mono&quot;, menlo, courier, monospace;font-size:14px;font-weight:500;margin:0px 2px;padding:2px 4px;">gpt-4-32k-0314</code> are 80k TPM and 400 RPM. <strong style="box-sizing:border-box;">We are unable to accommodate requests for rate limit increases due to capacity constraints.</strong> In its current state, the model is intended for experimentation and prototyping, not high volume production use cases.</p><div style="box-sizing:border-box;margin-bottom:16px;margin-top:30px;"><a href="https://platform.openai.com/docs/guides/rate-limits/how-do-rate-limits-work" style="box-sizing:border-box;color:rgb(16, 163, 127);cursor:pointer;text-decoration:none;display:inline-block;"><h3 style="box-sizing:border-box;color:rgb(32, 33, 35);font-weight:700;margin-bottom:0px;font-size:20px;line-height:28px;margin-top:0px;margin:0px;position:relative;">How do rate limits work?<img src="Rate%20Limits%20-%20OpenAI%20API.resources/svg_8.svg"/></h3></a></div><p style="box-sizing:border-box;margin-bottom:15px;margin-top:0px;line-height:1.5;">If your rate limit is 60 requests per minute and 150k <code style="box-sizing:border-box;background:rgba(237, 238, 241, 0.5);border:1px solid rgba(174, 174, 188, 0.2);border-radius:4px;font-family:&quot;Roboto Mono&quot;, sfmono-regular, consolas, &quot;liberation mono&quot;, menlo, courier, monospace;font-size:14px;font-weight:500;margin:0px 2px;padding:2px 4px;">davinci</code> tokens per minute, youâ€™ll be limited either by reaching the requests/min cap or running out of tokensâ€”whichever happens first. For example, if your max requests/min is 60, you should be able to send 1 request per second. If you send 1 request every 800ms, once you hit your rate limit, youâ€™d only need to make your program sleep 200ms in order to send one more request otherwise subsequent requests would fail. With the default of 3,000 requests/min, customers can effectively send 1 request every 20ms, or every .02 seconds.</p><div style="box-sizing:border-box;margin-bottom:16px;margin-top:30px;"><a href="https://platform.openai.com/docs/guides/rate-limits/what-happens-if-i-hit-a-rate-limit-error" style="box-sizing:border-box;color:rgb(16, 163, 127);cursor:pointer;text-decoration:none;display:inline-block;"><h3 style="box-sizing:border-box;color:rgb(32, 33, 35);font-weight:700;margin-bottom:0px;font-size:20px;line-height:28px;margin-top:0px;margin:0px;position:relative;">What happens if I hit a rate limit error?<img src="Rate%20Limits%20-%20OpenAI%20API.resources/svg_9.svg"/></h3></a></div><p style="box-sizing:border-box;margin-bottom:15px;margin-top:0px;line-height:1.5;">Rate limit errors look like this: </p><blockquote style="box-sizing:border-box;background:rgb(247, 247, 248);color:rgb(86, 88, 105);margin:0px 0px 15px;padding:0.8em;"><p style="box-sizing:border-box;line-height:1.5;margin:0px;">Rate limit reached for default-text-davinci-002 in organization org-{id} on requests per min. Limit: 20.000000 / min. Current: 24.000000 / min.</p></blockquote><p style="box-sizing:border-box;margin-bottom:15px;margin-top:0px;line-height:1.5;">If you hit a rate limit, it means you've made too many requests in a short period of time, and the API is refusing to fulfill further requests until a specified amount of time has passed.</p><div style="box-sizing:border-box;margin-bottom:16px;margin-top:30px;"><a href="https://platform.openai.com/docs/guides/rate-limits/rate-limits-vs-max_tokens" style="box-sizing:border-box;color:rgb(16, 163, 127);cursor:pointer;text-decoration:none;display:inline-block;"><h3 style="box-sizing:border-box;color:rgb(32, 33, 35);font-weight:700;margin-bottom:0px;font-size:20px;line-height:28px;margin-top:0px;margin:0px;position:relative;">Rate limits vs <code style="box-sizing:border-box;">max_tokens</code><img src="Rate%20Limits%20-%20OpenAI%20API.resources/svg_10.svg"/></h3></a></div><p style="box-sizing:border-box;margin-bottom:15px;margin-top:0px;line-height:1.5;">Each <a href="https://platform.openai.com/docs/models/overview" target="_blank" rel="noopener noreferrer" style="box-sizing:border-box;color:rgb(16, 163, 127);cursor:pointer;text-decoration:none;">model we offer</a> has a limited number of tokens that can be passed in as input when making a request. You cannot increase the maximum number of tokens a model takes in. For example, if you are using <code style="box-sizing:border-box;background:rgba(237, 238, 241, 0.5);border:1px solid rgba(174, 174, 188, 0.2);border-radius:4px;font-family:&quot;Roboto Mono&quot;, sfmono-regular, consolas, &quot;liberation mono&quot;, menlo, courier, monospace;font-size:14px;font-weight:500;margin:0px 2px;padding:2px 4px;">text-ada-001</code>, the maximum number of tokens you can send to this model is 2,048 tokens per request.</p><div style="box-sizing:border-box;margin-bottom:16px;margin-top:30px;"><a href="https://platform.openai.com/docs/guides/rate-limits/error-mitigation" style="box-sizing:border-box;color:rgb(16, 163, 127);cursor:pointer;text-decoration:none;display:inline-block;"><h2 style="box-sizing:border-box;color:rgb(32, 33, 35);font-weight:700;margin-bottom:0px;font-size:24px;line-height:32px;margin-top:0px;margin:0px;position:relative;">Error Mitigation<img src="Rate%20Limits%20-%20OpenAI%20API.resources/svg_11.svg"/></h2></a></div><div style="box-sizing:border-box;margin-bottom:16px;margin-top:30px;"><a href="https://platform.openai.com/docs/guides/rate-limits/what-are-some-steps-i-can-take-to-mitigate-this" style="box-sizing:border-box;color:rgb(16, 163, 127);cursor:pointer;text-decoration:none;display:inline-block;"><h3 style="box-sizing:border-box;color:rgb(32, 33, 35);font-weight:700;margin-bottom:0px;font-size:20px;line-height:28px;margin-top:0px;margin:0px;position:relative;">What are some steps I can take to mitigate this?<img src="Rate%20Limits%20-%20OpenAI%20API.resources/svg_12.svg"/></h3></a></div><p style="box-sizing:border-box;margin-bottom:15px;margin-top:0px;line-height:1.5;">The OpenAI Cookbook has a <a href="https://github.com/openai/openai-cookbook/blob/main/examples/How_to_handle_rate_limits.ipynb" target="_blank" rel="noopener noreferrer" style="box-sizing:border-box;color:rgb(16, 163, 127);cursor:pointer;text-decoration:none;">python notebook</a> that explains details on how to avoid rate limit errors.</p><p style="box-sizing:border-box;margin-bottom:15px;margin-top:0px;line-height:1.5;">You should also exercise caution when providing programmatic access, bulk processing features, and automated social media posting - consider only enabling these for trusted customers. </p><p style="box-sizing:border-box;margin-bottom:15px;margin-top:0px;line-height:1.5;">To protect against automated and high-volume misuse, set a usage limit for individual users within a specified time frame (daily, weekly, or monthly). Consider implementing a hard cap or a manual review process for users who exceed the limit. </p><div style="box-sizing:border-box;margin-bottom:16px;margin-top:30px;"><a href="https://platform.openai.com/docs/guides/rate-limits/retrying-with-exponential-backoff" style="box-sizing:border-box;color:rgb(16, 163, 127);cursor:pointer;text-decoration:none;display:inline-block;"><h4 style="box-sizing:border-box;color:rgb(32, 33, 35);font-weight:700;margin-bottom:0px;font-size:18px;line-height:24px;margin-top:0px;margin:0px;position:relative;">Retrying with exponential backoff<img src="Rate%20Limits%20-%20OpenAI%20API.resources/svg_13.svg"/></h4></a></div><p style="box-sizing:border-box;margin-bottom:15px;margin-top:0px;line-height:1.5;">One easy way to avoid rate limit errors is to automatically retry requests with a random exponential backoff. Retrying with exponential backoff means performing a short sleep when a rate limit error is hit, then retrying the unsuccessful request. If the request is still unsuccessful, the sleep length is increased and the process is repeated. This continues until the request is successful or until a maximum number of retries is reached.
This approach has many benefits:</p><ul style="box-sizing:border-box;list-style:none;padding-left:0px;"><li style="box-sizing:border-box;line-height:1.4;padding-left:32px;position:relative;">Automatic retries means you can recover from rate limit errors without crashes or missing data</li><li style="box-sizing:border-box;line-height:1.4;padding-left:32px;position:relative;margin-top:8px;">Exponential backoff means that your first retries can be tried quickly, while still benefiting from longer delays if your first few retries fail</li><li style="box-sizing:border-box;line-height:1.4;padding-left:32px;position:relative;margin-top:8px;">Adding random jitter to the delay helps retries from all hitting at the same time.</li></ul><p style="box-sizing:border-box;margin-bottom:15px;margin-top:0px;line-height:1.5;">Note that unsuccessful requests contribute to your per-minute limit, so continuously resending a request wonâ€™t work.</p><p style="box-sizing:border-box;margin-bottom:15px;margin-top:0px;line-height:1.5;">Below are a few example solutions <strong style="box-sizing:border-box;">for Python</strong> that use exponential backoff.</p><div style="box-sizing:border-box;border-bottom:1px solid rgb(217, 217, 227);"><div style="box-sizing:border-box;font-feature-settings:&quot;tnum&quot;;align-items:center;cursor:pointer;display:flex;flex-direction:row;font-size:20px;font-variant-numeric:tabular-nums;font-weight:700;justify-content:flex-start;line-height:1.4;padding:26px 14px 26px 24px;transition:color 0.3s ease 0s;"><div style="box-sizing:border-box;flex:1 1 auto;">Example #1: Using the Tenacity library</div><div style="box-sizing:border-box;align-items:center;display:flex;flex:0 0 auto;font-size:22px;justify-content:center;"><img src="Rate%20Limits%20-%20OpenAI%20API.resources/svg_14.svg"/></div></div></div><div style="box-sizing:border-box;border-bottom:1px solid rgb(217, 217, 227);"><div style="box-sizing:border-box;font-feature-settings:&quot;tnum&quot;;align-items:center;cursor:pointer;display:flex;flex-direction:row;font-size:20px;font-variant-numeric:tabular-nums;font-weight:700;justify-content:flex-start;line-height:1.4;padding:26px 14px 26px 24px;transition:color 0.3s ease 0s;"><div style="box-sizing:border-box;flex:1 1 auto;">Example #2: Using the backoff library</div><div style="box-sizing:border-box;align-items:center;display:flex;flex:0 0 auto;font-size:22px;justify-content:center;"><img src="Rate%20Limits%20-%20OpenAI%20API.resources/svg_15.svg"/></div></div></div><div style="box-sizing:border-box;border-bottom:1px solid rgb(217, 217, 227);"><div style="box-sizing:border-box;font-feature-settings:&quot;tnum&quot;;align-items:center;cursor:pointer;display:flex;flex-direction:row;font-size:20px;font-variant-numeric:tabular-nums;font-weight:700;justify-content:flex-start;line-height:1.4;padding:26px 14px 26px 24px;transition:color 0.3s ease 0s;"><div style="box-sizing:border-box;flex:1 1 auto;">Example 3: Manual backoff implementation</div><div style="box-sizing:border-box;align-items:center;display:flex;flex:0 0 auto;font-size:22px;justify-content:center;"><img src="Rate%20Limits%20-%20OpenAI%20API.resources/svg_16.svg"/></div></div></div><div style="box-sizing:border-box;margin-bottom:16px;margin-top:30px;"><a href="https://platform.openai.com/docs/guides/rate-limits/batching-requests" style="box-sizing:border-box;color:rgb(16, 163, 127);cursor:pointer;text-decoration:none;display:inline-block;"><h4 style="box-sizing:border-box;color:rgb(32, 33, 35);font-weight:700;margin-bottom:0px;font-size:18px;line-height:24px;margin-top:0px;margin:0px;position:relative;">Batching requests<img src="Rate%20Limits%20-%20OpenAI%20API.resources/svg_17.svg"/></h4></a></div><p style="box-sizing:border-box;margin-bottom:15px;margin-top:0px;line-height:1.5;">The OpenAI API has separate limits for requests per minute and tokens per minute.Â </p><p style="box-sizing:border-box;margin-bottom:15px;margin-top:0px;line-height:1.5;">If you're hitting the limit on requests per minute, but have available capacity on tokens per minute, you can increase your throughput by batching multiple tasks into each request. This will allow you to process more tokens per minute, especially with our smaller models.</p><p style="box-sizing:border-box;margin-bottom:15px;margin-top:0px;line-height:1.5;">Sending in a batch of prompts works exactly the same as a normal API call, except you pass in a list of strings to the prompt parameter instead of a single string.</p><div style="box-sizing:border-box;border-bottom:1px solid rgb(217, 217, 227);"><div style="box-sizing:border-box;font-feature-settings:&quot;tnum&quot;;align-items:center;cursor:pointer;display:flex;flex-direction:row;font-size:20px;font-variant-numeric:tabular-nums;font-weight:700;justify-content:flex-start;line-height:1.4;padding:26px 14px 26px 24px;transition:color 0.3s ease 0s;"><div style="box-sizing:border-box;flex:1 1 auto;">Example without batching</div><div style="box-sizing:border-box;align-items:center;display:flex;flex:0 0 auto;font-size:22px;justify-content:center;"><img src="Rate%20Limits%20-%20OpenAI%20API.resources/svg_18.svg"/></div></div></div><div style="box-sizing:border-box;border-bottom:1px solid rgb(217, 217, 227);"><div style="box-sizing:border-box;font-feature-settings:&quot;tnum&quot;;align-items:center;cursor:pointer;display:flex;flex-direction:row;font-size:20px;font-variant-numeric:tabular-nums;font-weight:700;justify-content:flex-start;line-height:1.4;padding:26px 14px 26px 24px;transition:color 0.3s ease 0s;"><div style="box-sizing:border-box;flex:1 1 auto;">Example with batching</div><div style="box-sizing:border-box;align-items:center;display:flex;flex:0 0 auto;font-size:22px;justify-content:center;"><img src="Rate%20Limits%20-%20OpenAI%20API.resources/svg_19.svg"/></div></div></div><div style="box-sizing:border-box;margin-top:24px;margin-bottom:24px;"><div style="box-sizing:border-box;border:1px solid rgb(236, 236, 241);border-radius:4px;flex:0 0 auto;min-width:275px;padding:16px 18px;position:relative;text-align:center;width:100%;align-items:center;display:inline-flex;background-color:rgb(247, 247, 248);border-color:rgb(236, 236, 241);"><div style="box-sizing:border-box;font-size:20px;display:inline-flex;flex:0 0 auto;margin-right:14px;color:rgb(110, 110, 128);align-self:flex-start;"><img src="Rate%20Limits%20-%20OpenAI%20API.resources/svg_20.svg"/></div><div style="box-sizing:border-box;color:rgb(32, 33, 35);margin-bottom:-2px;text-align:left;flex:1 1 auto;"><div style="box-sizing:border-box;"> Warning: the response object may not return completions in the order of the prompts, so always remember to match responses back to prompts using the index field.</div></div></div></div><div style="box-sizing:border-box;margin-bottom:16px;margin-top:30px;"><a href="https://platform.openai.com/docs/guides/rate-limits/request-increase" style="box-sizing:border-box;color:rgb(16, 163, 127);cursor:pointer;text-decoration:none;display:inline-block;"><h2 style="box-sizing:border-box;color:rgb(32, 33, 35);font-weight:700;margin-bottom:0px;font-size:24px;line-height:32px;margin-top:0px;margin:0px;position:relative;">Request Increase<img src="Rate%20Limits%20-%20OpenAI%20API.resources/svg_21.svg"/></h2></a></div><div style="box-sizing:border-box;margin-bottom:16px;margin-top:30px;"><a href="https://platform.openai.com/docs/guides/rate-limits/when-should-i-consider-applying-for-a-rate-limit-increase" style="box-sizing:border-box;color:rgb(16, 163, 127);cursor:pointer;text-decoration:none;display:inline-block;"><h3 style="box-sizing:border-box;color:rgb(32, 33, 35);font-weight:700;margin-bottom:0px;font-size:20px;line-height:28px;margin-top:0px;margin:0px;position:relative;">When should I consider applying for a rate limit increase?<img src="Rate%20Limits%20-%20OpenAI%20API.resources/svg_22.svg"/></h3></a></div><p style="box-sizing:border-box;margin-bottom:15px;margin-top:0px;line-height:1.5;">Our default rate limits help us maximize stability and prevent abuse of our API. We increase limits to enable high-traffic applications, so the best time to apply for a rate limit increase is when you feel that you have the necessary traffic data to support a strong case for increasing the rate limit. Large rate limit increase requests without supporting data are not likely to be approved. If you're gearing up for a product launch, please obtain the relevant data through a phased release over 10 days.</p><p style="box-sizing:border-box;margin-bottom:15px;margin-top:0px;line-height:1.5;">Keep in mind that rate limit increases can sometimes take 7-10 days so it makes sense to try and plan ahead and submit early if there is data to support you will reach your rate limit given your current growth numbers.</p><div style="box-sizing:border-box;margin-bottom:16px;margin-top:30px;"><a href="https://platform.openai.com/docs/guides/rate-limits/will-my-rate-limit-increase-request-be-rejected" style="box-sizing:border-box;color:rgb(16, 163, 127);cursor:pointer;text-decoration:none;display:inline-block;"><h3 style="box-sizing:border-box;color:rgb(32, 33, 35);font-weight:700;margin-bottom:0px;font-size:20px;line-height:28px;margin-top:0px;margin:0px;position:relative;">Will my rate limit increase request be rejected?<img src="Rate%20Limits%20-%20OpenAI%20API.resources/svg_23.svg"/></h3></a></div><p style="box-sizing:border-box;margin-bottom:15px;margin-top:0px;line-height:1.5;">A rate limit increase request is most often rejected because it lacks the data needed to justify the increase. We have provided numerical examples below that show how to best support a rate limit increase request and try our best to approve all requests that align with our safety policy and show supporting data. We are committed to enabling developers to scale and be successful with our API.</p><div style="box-sizing:border-box;margin-bottom:16px;margin-top:30px;"><a href="https://platform.openai.com/docs/guides/rate-limits/i-ve-implemented-exponential-backoff-for-my-text-code-apis-but-i-m-still-hitting-this-error-how-do-i-increase-my-rate-limit" style="box-sizing:border-box;color:rgb(16, 163, 127);cursor:pointer;text-decoration:none;display:inline-block;"><h3 style="box-sizing:border-box;color:rgb(32, 33, 35);font-weight:700;margin-bottom:0px;font-size:20px;line-height:28px;margin-top:0px;margin:0px;position:relative;">Iâ€™ve implemented exponential backoff for my text/code APIs, but Iâ€™m still hitting this error. How do I increase my rate limit?<img src="Rate%20Limits%20-%20OpenAI%20API.resources/svg_24.svg"/></h3></a></div><p style="box-sizing:border-box;margin-bottom:15px;margin-top:0px;line-height:1.5;">We understand the frustration that limited rate limits can cause, and we would love to raise the defaults for everyone. However, due to shared capacity constraints, we can only approve rate limit increases for paid customers who have demonstrated a need through our <a href="https://docs.google.com/forms/d/e/1FAIpQLSc6gSL3zfHFlL6gNIyUcjkEv29jModHGxg5_XGyr-PrE2LaHw/viewform" target="_blank" rel="noopener noreferrer" style="box-sizing:border-box;color:rgb(16, 163, 127);cursor:pointer;text-decoration:none;">Rate Limit Increase Request form</a>.
To help us evaluate your needs properly, we ask that you please provide statistics on your current usage or projections based on historic user activity in the 'Share evidence of need' section of the form. If this information is not available, we recommend a phased release approach. Start by releasing the service to a subset of users at your current rate limits, gather usage data for 10 business days, and then submit a formal rate limit increase request based on that data for our review and approval.</p><p style="box-sizing:border-box;margin-bottom:15px;margin-top:0px;line-height:1.5;">We will review your request and if it is approved, we will notify you of the approval within a period of 7-10 business days.</p><p style="box-sizing:border-box;margin-bottom:15px;margin-top:0px;line-height:1.5;">Here are some examples of how you might fill out this form:</p><div style="box-sizing:border-box;border-bottom:1px solid rgb(217, 217, 227);"><div style="box-sizing:border-box;font-feature-settings:&quot;tnum&quot;;align-items:center;cursor:pointer;display:flex;flex-direction:row;font-size:20px;font-variant-numeric:tabular-nums;font-weight:700;justify-content:flex-start;line-height:1.4;padding:26px 14px 26px 24px;transition:color 0.3s ease 0s;"><div style="box-sizing:border-box;flex:1 1 auto;">DALL-E API examples</div><div style="box-sizing:border-box;align-items:center;display:flex;flex:0 0 auto;font-size:22px;justify-content:center;"><img src="Rate%20Limits%20-%20OpenAI%20API.resources/svg_25.svg"/></div></div></div><div style="box-sizing:border-box;border-bottom:1px solid rgb(217, 217, 227);"><div style="box-sizing:border-box;font-feature-settings:&quot;tnum&quot;;align-items:center;cursor:pointer;display:flex;flex-direction:row;font-size:20px;font-variant-numeric:tabular-nums;font-weight:700;justify-content:flex-start;line-height:1.4;padding:26px 14px 26px 24px;transition:color 0.3s ease 0s;"><div style="box-sizing:border-box;flex:1 1 auto;">Language model examples</div><div style="box-sizing:border-box;align-items:center;display:flex;flex:0 0 auto;font-size:22px;justify-content:center;"><img src="Rate%20Limits%20-%20OpenAI%20API.resources/svg_26.svg"/></div></div></div><div style="box-sizing:border-box;border-bottom:1px solid rgb(217, 217, 227);"><div style="box-sizing:border-box;font-feature-settings:&quot;tnum&quot;;align-items:center;cursor:pointer;display:flex;flex-direction:row;font-size:20px;font-variant-numeric:tabular-nums;font-weight:700;justify-content:flex-start;line-height:1.4;padding:26px 14px 26px 24px;transition:color 0.3s ease 0s;"><div style="box-sizing:border-box;flex:1 1 auto;">Code model examples</div><div style="box-sizing:border-box;align-items:center;display:flex;flex:0 0 auto;font-size:22px;justify-content:center;"><img src="Rate%20Limits%20-%20OpenAI%20API.resources/svg_27.svg"/></div></div></div><br style="box-sizing:border-box;"/>Please note that these examples are just general use case scenarios, the actual usage rate will vary depending on the specific implementation and usage.</div></div></div></div></div></div></div></div></div>
</div>
</body></html>